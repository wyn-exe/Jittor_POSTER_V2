# POSTER V2: Jittor å¤ç°

è¿™æ˜¯è®ºæ–‡ **POSTER V2** çš„å®Œæ•´ Jittor å¤ç°é¡¹ç›®ã€‚POSTER V2 æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„é¢éƒ¨è¡¨æƒ…è¯†åˆ«ï¼ˆFacial Expression Recognition, FERï¼‰æ¨¡å‹ï¼Œé€šè¿‡ç²¾ç®€æ¶æ„å’Œåˆ›æ–°çš„ç‰¹å¾èåˆæœºåˆ¶ï¼Œåœ¨ä¿æŒ SOTA æ€§èƒ½çš„åŒæ—¶å¤§å¹…é™ä½äº†è®¡ç®—æˆæœ¬ã€‚

---

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### æ ¸å¿ƒåˆ›æ–°

POSTER V2 ç›¸æ¯” POSTER V1 çš„ä¸»è¦æ”¹è¿›ï¼š

- **æ¶æ„ç®€åŒ–**ï¼šç§»é™¤è®¡ç®—æ˜‚è´µçš„"å›¾åƒåˆ°åœ°æ ‡"åˆ†æ”¯ï¼Œä»…ä¿ç•™é«˜æ•ˆçš„"åœ°æ ‡åˆ°å›¾åƒ"ä¿¡æ¯æµ
- **å‚æ•°å‡å°‘**ï¼šå‡å°‘ 28.1M å‚æ•°
- **è®¡ç®—ä¼˜åŒ–**ï¼šFLOPs å‡å°‘ 7.3G
- **æ€§èƒ½ä¿æŒ**ï¼šåœ¨ RAF-DBã€AffectNetã€CAER-S ç­‰æ ‡å‡†æ•°æ®é›†ä¸Šè¾¾åˆ° SOTA æ€§èƒ½

### æ¨¡å‹æ¶æ„

```
è¾“å…¥å›¾åƒ (224Ã—224)
    â†“
    â”œâ”€â†’ å›¾åƒä¸»å¹²ç½‘ç»œ (IR50) â”€â”€â†’ å¤šå°ºåº¦ç‰¹å¾ [C1, C2, C3]
    â”‚
    â””â”€â†’ é¢éƒ¨å…³é”®ç‚¹æ£€æµ‹å™¨ (MobileFaceNet) â”€â”€â†’ å¤šå°ºåº¦ç‰¹å¾ [L1, L2, L3]

    â†“

çª—å£åŒ–è·¨æ³¨æ„åŠ›èåˆ (W-MCSA)
    â†“
èåˆç‰¹å¾ [F1, F2, F3]
    â†“
æµ…å±‚ Vision Transformer (æ·±åº¦=2)
    â†“
è¡¨æƒ…åˆ†ç±»è¾“å‡º (7ç±»æˆ–8ç±»)
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®

#### 1. å®‰è£… Jittor

```bash
# å®˜æ–¹å®‰è£…æŒ‡å—ï¼šhttps://cg.cs.tsinghua.edu.cn/jittor/

# Linux/Mac
python -m pip install jittor

# Windows (æ¨èä½¿ç”¨ WSL2 æˆ– Linux ç¯å¢ƒ)
python -m pip install jittor
```

#### 2. å®‰è£…ä¾èµ–

```bash
pip install -r requirements_jittor.txt
```

**ä¾èµ–åˆ—è¡¨ï¼š**

- jittor >= 1.3.0
- numpy >= 1.22.0
- scikit-learn >= 1.0.0
- matplotlib >= 3.6.0
- Pillow >= 9.0.0
- opencv-python >= 4.6.0
- tqdm >= 4.64.0

### æ•°æ®é›†å‡†å¤‡

#### æ”¯æŒçš„æ•°æ®é›†

é¡¹ç›®æ”¯æŒä»¥ä¸‹ä¸‰ä¸ªæ ‡å‡†é¢éƒ¨è¡¨æƒ…è¯†åˆ«æ•°æ®é›†ï¼š

1. **RAF-DB** (Real-world Affective Faces Database)
   - ç°å®ä¸–ç•Œæƒ…æ„Ÿé¢å­”æ•°æ®åº“ï¼ˆRAF-DBï¼‰æ˜¯ä¸€ä¸ªé¢éƒ¨è¡¨æƒ…æ•°æ®é›†ã€‚è¯¥ç‰ˆæœ¬åŒ…å«15000kå¼ é¢éƒ¨å›¾åƒï¼Œç”±40ä¸ªç‹¬ç«‹æ ‡æ³¨å™¨æ ‡è®°åŸºæœ¬æˆ–å¤åˆè¡¨æƒ…ã€‚è¯¥æ•°æ®åº“ä¸­çš„å›¾åƒåœ¨å—è¯•è€…å¹´é¾„ã€æ€§åˆ«å’Œæ—è£”ã€å¤´éƒ¨å§¿åŠ¿ã€å…‰çº¿æ¡ä»¶ã€é®æŒ¡ï¼ˆå¦‚çœ¼é•œã€èƒ¡é¡»æˆ–è‡ªé—­ï¼‰ã€åæœŸå¤„ç†ï¼ˆå¦‚å„ç§æ»¤é•œå’Œç‰¹æ•ˆï¼‰ç­‰æ–¹é¢å·®å¼‚å¾ˆå¤§ã€‚
   - ä¸‹è½½åœ°å€ï¼š[RAF-DB DATASET](https://www.kaggle.com/datasets/shuvoalok/raf-db-dataset?resource=download)

2. **AffectNet-7** (7 ç±»ç‰ˆæœ¬)

3. **CAER-S** (Context-Aware Emotion Recognition)

#### æ•°æ®é›†ç›®å½•ç»“æ„

```
data/
â”œâ”€â”€ RAF-DB/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ 0/  (Surprise)
â”‚   â”‚   â”œâ”€â”€ 1/  (Fear)
â”‚   â”‚   â”œâ”€â”€ 2/  (Disgust)
â”‚   â”‚   â”œâ”€â”€ 3/  (Happiness)
â”‚   â”‚   â”œâ”€â”€ 4/  (Sadness)
â”‚   â”‚   â”œâ”€â”€ 5/  (Anger)
â”‚   â”‚   â””â”€â”€ 6/  (Neutral)
â”‚   â””â”€â”€ valid/
â”‚       â”œâ”€â”€ 0/
â”‚       â”œâ”€â”€ 1/
â”‚       â””â”€â”€ ...
â””â”€â”€ val_datasets/
    â””â”€â”€ (å…¶ä»–éªŒè¯æ•°æ®é›†)
```

### é¢„è®­ç»ƒæƒé‡

é¡¹ç›®ä½¿ç”¨ä¸¤ä¸ªå…³é”®çš„é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ï¼Œå·²åŒ…å«åœ¨ `models/pretrain/` ç›®å½•ä¸­ï¼š

| æ–‡ä»¶å                             | ç”¨é€”             | è¯´æ˜                                   |
| ---------------------------------- | ---------------- | -------------------------------------- |
| `ir50.pth`                         | å›¾åƒä¸»å¹²ç½‘ç»œ     | åŸºäº IR50 æ¶æ„ï¼Œæå–å…¨å±€è§†è§‰ç‰¹å¾       |
| `mobilefacenet_model_best.pth.tar` | é¢éƒ¨å…³é”®ç‚¹æ£€æµ‹å™¨ | åŸºäº MobileFaceNetï¼Œæå–å±€éƒ¨å…³é”®ç‚¹ç‰¹å¾ |

**é‡è¦**ï¼šMobileFaceNet åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‚æ•°è¢«å†»ç»“ï¼ˆ`requires_grad=False`ï¼‰ï¼Œä»…ä½œä¸ºç‰¹å¾æå–å™¨ä½¿ç”¨ã€‚
ir50.pthä¸åœ¨ä»“åº“ä¸­ï¼Œè¯·ä¸‹è½½åæ”¾ç½®äºJittor_POSTER/models/pretrain/ ä¸‹ã€‚
ä¸‹è½½é“¾æ¥: (https://pan.baidu.com/s/1zoI59qLV93kX2uZrIwdrRA?pwd=ir50) æå–ç : ir50

## ğŸ“š ä½¿ç”¨æŒ‡å—

### è®­ç»ƒæ¨¡å‹

#### åŸºç¡€è®­ç»ƒï¼ˆRAF-DB æ•°æ®é›†ï¼Œ7 ç±»åˆ†ç±»ï¼‰

```bash
python main.py \
    --data /path/to/RAF-DB \
    --data_type RAF-DB \
    --epochs 200 \
    --batch-size 144 \
    --lr 0.000035 \
    --gpu 0
```

#### è®­ç»ƒå‚æ•°è¯´æ˜

| å‚æ•°           | é»˜è®¤å€¼              | è¯´æ˜                                          |
| -------------- | ------------------- | --------------------------------------------- |
| `--data`       | `/home/Dataset/RAF` | æ•°æ®é›†è·¯å¾„                                    |
| `--data_type`  | `RAF-DB`            | æ•°æ®é›†ç±»å‹ï¼š`RAF-DB`, `AffectNet-7`, `CAER-S` |
| `--epochs`     | `200`               | è®­ç»ƒæ€»è½®æ•°                                    |
| `--batch-size` | `144`               | æ‰¹æ¬¡å¤§å°                                      |
| `--lr`         | `0.000035`          | åˆå§‹å­¦ä¹ ç‡                                    |
| `--optimizer`  | `adam`              | ä¼˜åŒ–å™¨ï¼š`adam`, `adamw`, `sgd`                |
| `--momentum`   | `0.9`               | SGD åŠ¨é‡ï¼ˆä»…åœ¨ä½¿ç”¨ SGD æ—¶æœ‰æ•ˆï¼‰               |
| `--wd`         | `1e-4`              | æƒé‡è¡°å‡                                      |
| `--workers`    | `0`                 | æ•°æ®åŠ è½½çº¿ç¨‹æ•°                                |
| `--gpu`        | `0`                 | GPU è®¾å¤‡ ID                                   |
| `--resume`     | `None`              | æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„                          |
| `--evaluate`   | `None`              | ä»…è¯„ä¼°æ¨¡å¼ï¼ŒæŒ‡å®šæ¨¡å‹è·¯å¾„                      |
| `--beta`       | `0.6`               | æ ‡ç­¾å¹³æ»‘å‚æ•°                                  |

#### å…¶ä»–æ•°æ®é›†è®­ç»ƒ

```bash
# AffectNet-7
python main.py \
    --data /path/to/AffectNet \
    --data_type AffectNet-7 \
    --batch-size 144

# CAER-S
python main.py \
    --data /path/to/CAER-S \
    --data_type CAER-S \
    --batch-size 144
```

#### 8 ç±»åˆ†ç±»è®­ç»ƒ

å¯¹äº 8 ç±»è¡¨æƒ…åˆ†ç±»ï¼ˆå¦‚æŸäº›æ•°æ®é›†çš„æ‰©å±•ç‰ˆæœ¬ï¼‰ï¼Œä½¿ç”¨ `main_8.py`ï¼š

```bash
python main_8.py \
    --data /path/to/dataset \
    --data_type RAF-DB \
    --epochs 200 \
    --batch-size 144
```

### æ¢å¤è®­ç»ƒ

å¦‚æœè®­ç»ƒè¢«ä¸­æ–­ï¼Œå¯ä»¥ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼š

```bash
python main.py \
    --data /path/to/RAF-DB \
    --resume ./checkpoint/[timestamp]model.pth \
    --epochs 200
```

### æ¨¡å‹è¯„ä¼°

#### ä»…è¯„ä¼°æ¨¡å¼

```bash
python main.py \
    --data /path/to/RAF-DB \
    --evaluate ./checkpoint/[timestamp]model_best.pth
```

æ­¤æ¨¡å¼å°†åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼Œè¾“å‡ºå‡†ç¡®ç‡å’Œæ··æ·†çŸ©é˜µã€‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
Jittor_POSTER/
â”œâ”€â”€ README.md                          # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ requirements_jittor.txt            # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ main.py                            # 7 ç±»åˆ†ç±»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ main_8.py                          # 8 ç±»åˆ†ç±»è®­ç»ƒè„šæœ¬
â”‚
â”œâ”€â”€ models/                            # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ PosterV2_7cls.py              # 7 ç±» POSTER V2 æ¨¡å‹
â”‚   â”œâ”€â”€ PosterV2_8cls.py              # 8 ç±» POSTER V2 æ¨¡å‹
â”‚   â”œâ”€â”€ ir50.py                       # IR50 ä¸»å¹²ç½‘ç»œ
â”‚   â”œâ”€â”€ mobilefacenet.py              # MobileFaceNet å…³é”®ç‚¹æ£€æµ‹å™¨
â”‚   â”œâ”€â”€ vit_model.py                  # Vision Transformer (7 ç±»)
â”‚   â”œâ”€â”€ vit_model_8.py                # Vision Transformer (8 ç±»)
â”‚   â”œâ”€â”€ matrix.py                     # çŸ©é˜µæ“ä½œå·¥å…·
â”‚   â”œâ”€â”€ load_pth.py                   # æƒé‡åŠ è½½å·¥å…·
â”‚   â””â”€â”€ pretrain/                     # é¢„è®­ç»ƒæƒé‡
â”‚       â”œâ”€â”€ ir50.pth
â”‚       â”œâ”€â”€ mobilefacenet_model_best.pth
â”‚       â””â”€â”€ mobilefacenet_model_best.pth.tar
â”‚
â”œâ”€â”€ data_preprocessing/                # æ•°æ®é¢„å¤„ç†
â”‚   â””â”€â”€ sam.py                        # SAM ä¼˜åŒ–å™¨å®ç°
â”‚
â”œâ”€â”€ data/                              # æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ RAF-DB/
â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ valid/
â”‚   â””â”€â”€ val_datasets/
â”‚
â”œâ”€â”€ checkpoint/                        # è®­ç»ƒæ£€æŸ¥ç‚¹
â”‚   â””â”€â”€ (è‡ªåŠ¨ç”Ÿæˆ)
â”‚
â””â”€â”€ log/                               # è®­ç»ƒæ—¥å¿—
    â””â”€â”€ (è‡ªåŠ¨ç”Ÿæˆ)
```

## ğŸ”§ æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. POSTER V2 æ¨¡å‹ (`models/PosterV2_7cls.py`)

**ä¸»è¦ç±»ï¼š`pyramid_trans_expr2`**

```python
model = pyramid_trans_expr2(img_size=224, num_classes=7)
```

**å…³é”®ç»„ä»¶ï¼š**

- **window æ¨¡å—**ï¼šçª—å£åˆ†å‰²å’Œå½’ä¸€åŒ–
- **WindowAttentionGlobal**ï¼šçª—å£åŒ–è·¨æ³¨æ„åŠ›æœºåˆ¶
- **å¤šå°ºåº¦ç‰¹å¾èåˆ**ï¼šåœ¨ä¸‰ä¸ªä¸åŒå°ºåº¦ä¸Šèåˆå›¾åƒå’Œå…³é”®ç‚¹ç‰¹å¾
- **æµ…å±‚ ViT**ï¼šæ·±åº¦ä¸º 2 çš„ Vision Transformer è¿›è¡Œæœ€ç»ˆåˆ†ç±»

### 2. ä¼˜åŒ–å™¨ - SAM (`data_preprocessing/sam.py`)

**Sharpness Aware Minimization (SAM) ä¼˜åŒ–å™¨**

SAM é€šè¿‡ä¸¤æ­¥ä¼˜åŒ–è¿‡ç¨‹æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼š

```python
optimizer = SAM(model.parameters(), base_optimizer, lr=0.000035, rho=0.05)

# è®­ç»ƒå¾ªç¯
for images, targets in train_loader:
    output = model(images)
    loss = criterion(output, targets)

    # ç¬¬ä¸€æ­¥ï¼šè®¡ç®—æ¢¯åº¦å¹¶æ‰°åŠ¨æƒé‡
    optimizer.first_step(loss)

    # ç¬¬äºŒæ­¥ï¼šåœ¨æ‰°åŠ¨ç‚¹è®¡ç®—æ¢¯åº¦ï¼Œæ¢å¤å¹¶æ›´æ–°æƒé‡
    output = model(images)
    loss = criterion(output, targets)
    optimizer.second_step(loss)
```

**å‚æ•°è¯´æ˜ï¼š**

- `rho`ï¼šæ‰°åŠ¨åŠå¾„ï¼ˆé»˜è®¤ 0.05ï¼‰
- `adaptive`ï¼šæ˜¯å¦ä½¿ç”¨è‡ªé€‚åº” SAMï¼ˆé»˜è®¤ Falseï¼‰

### 3. æ•°æ®å¢å¼º

**RandomErasing**ï¼šéšæœºæ“¦é™¤å¢å¼º

```python
RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))
```

- `p`ï¼šåº”ç”¨æ¦‚ç‡
- `scale`ï¼šæ“¦é™¤åŒºåŸŸç›¸å¯¹äºå›¾åƒé¢ç§¯çš„æ¯”ä¾‹èŒƒå›´
- `ratio`ï¼šæ“¦é™¤åŒºåŸŸçš„å®½é«˜æ¯”èŒƒå›´

**ä¸åŒæ•°æ®é›†çš„å¢å¼ºç­–ç•¥ï¼š**

| æ•°æ®é›†      | RandomErasing å‚æ•°         |
| ----------- | -------------------------- |
| RAF-DB      | `p=0.5, scale=(0.02, 0.1)` |
| AffectNet-7 | `p=1, scale=(0.05, 0.05)`  |
| CAER-S      | `p=1, scale=(0.05, 0.05)`  |

### 4. æƒé‡åŠ è½½ (`models/load_pth.py`)

è‡ªåŠ¨åŠ è½½é¢„è®­ç»ƒæƒé‡åˆ° Jittor æ¨¡å‹ã€‚

## ğŸ“Š è®­ç»ƒè¾“å‡º

### æ—¥å¿—æ–‡ä»¶

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆæ—¥å¿—æ–‡ä»¶ï¼š`log/[timestamp]log.txt`

**æ—¥å¿—å†…å®¹ç¤ºä¾‹ï¼š**

```
Current learning rate: 3.5e-05
Epoch: [0][0/100]	Loss 2.1234 (2.1234)	Accuracy 28.571 (28.571)
Epoch: [0][30/100]	Loss 1.8765 (1.9234)	Accuracy 42.857 (38.571)
...
 * Accuracy 65.432
Current best accuracy: 65.432
```

### æ£€æŸ¥ç‚¹æ–‡ä»¶

- `checkpoint/[timestamp]model.pth`ï¼šæœ€æ–°æ£€æŸ¥ç‚¹ï¼ˆåŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰
- `checkpoint/[timestamp]model_best.pth`ï¼šæœ€ä½³æ¨¡å‹ï¼ˆä»…åŒ…å«æ¨¡å‹æƒé‡ï¼‰

**æ£€æŸ¥ç‚¹å†…å®¹ï¼š**

```python
{
    'epoch': int,                    # å½“å‰è½®æ•°
    'state_dict': model.state_dict(),  # æ¨¡å‹æƒé‡
    'best_acc': float,               # æœ€ä½³å‡†ç¡®ç‡
    'optimizer': optimizer.state_dict(),  # ä¼˜åŒ–å™¨çŠ¶æ€
    'recorder': RecorderMeter,       # è®­ç»ƒè®°å½•
    'recorder1': RecorderMeter1      # æ··æ·†çŸ©é˜µè®°å½•
}
```

### å¯è§†åŒ–è¾“å‡º

- `log/[timestamp]cnn.png`ï¼šè®­ç»ƒ/éªŒè¯å‡†ç¡®ç‡å’ŒæŸå¤±æ›²çº¿
- `log/confusion_matrix.png`ï¼šæ··æ·†çŸ©é˜µçƒ­åŠ›å›¾

## ğŸ¯ æ€§èƒ½æŒ‡æ ‡

### è¯„ä¼°æŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¸­è®¡ç®—ä»¥ä¸‹æŒ‡æ ‡ï¼š

- **å‡†ç¡®ç‡ (Accuracy)**ï¼šæ­£ç¡®åˆ†ç±»çš„æ ·æœ¬æ¯”ä¾‹
- **F1 åˆ†æ•°**ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡æ•°
- **æ··æ·†çŸ©é˜µ**ï¼šå„ç±»åˆ«é—´çš„åˆ†ç±»æƒ…å†µ

### é¢„æœŸæ€§èƒ½

åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼ˆå‚è€ƒè®ºæ–‡ï¼‰ï¼š

| æ•°æ®é›†      | å‡†ç¡®ç‡ |
| ----------- | ------ |
| RAF-DB      | ~90%   |
| AffectNet-7 | ~65%   |
| CAER-S      | ~68%   |

*å®é™…æ€§èƒ½å¯èƒ½å› è®­ç»ƒé…ç½®ã€æ•°æ®é¢„å¤„ç†ç­‰å› ç´ ç•¥æœ‰å·®å¼‚*

## âš¡ å¿«é€Ÿå‚è€ƒå¡ç‰‡

### å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

```bash
# åŸºç¡€è®­ç»ƒ
python main.py --data /path/to/RAF-DB --epochs 200 --batch-size 144

# ä½¿ç”¨ä¸åŒä¼˜åŒ–å™¨
python main.py --data /path/to/data --optimizer adamw --lr 0.00005
python main.py --data /path/to/data --optimizer sgd --lr 0.01 --momentum 0.9

# æ¢å¤è®­ç»ƒ
python main.py --data /path/to/data --resume ./checkpoint/model.pth

# ä»…è¯„ä¼°
python main.py --data /path/to/data --evaluate ./checkpoint/model_best.pth

# 8 ç±»åˆ†ç±»
python main_8.py --data /path/to/data --epochs 200

# å¤šæ•°æ®é›†å¿«é€Ÿåˆ‡æ¢
python main.py --data /path/to/AffectNet --data_type AffectNet-7
python main.py --data /path/to/CAER-S --data_type CAER-S

# è°ƒæ•´å­¦ä¹ ç‡å’Œæ‰¹æ¬¡
python main.py --data /path/to/data --lr 0.00001 --batch-size 64

# æŒ‡å®š GPU
python main.py --data /path/to/data --gpu 0
python main.py --data /path/to/data --gpu 1
```

---

## ğŸ”§ æ•…éšœæ’é™¤æŒ‡å—

### é—®é¢˜ 1: ImportError: No module named 'jittor'

**ç—‡çŠ¶ï¼š**

```
ImportError: No module named 'jittor'
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# ç¡®ä¿ Jittor å·²æ­£ç¡®å®‰è£…
python -m pip install --upgrade jittor

# éªŒè¯å®‰è£…
python -c "import jittor; print(jittor.__version__)"

# å¦‚æœä»ç„¶å¤±è´¥ï¼Œå°è¯•é‡æ–°å®‰è£…
pip uninstall jittor -y
pip install jittor
```

### é—®é¢˜ 2: CUDA ç›¸å…³é”™è¯¯

**ç—‡çŠ¶ï¼š**

```
RuntimeError: CUDA out of memory
RuntimeError: CUDA is not available
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ£€æŸ¥ CUDA å¯ç”¨æ€§
python -c "import jittor as jt; print(jt.has_cuda)"

# å‡å°æ‰¹æ¬¡å¤§å°
python main.py --data /path/to/data --batch-size 32

# ä½¿ç”¨ CPUï¼ˆä¸æ¨èï¼Œé€Ÿåº¦æ…¢ï¼‰
python main.py --data /path/to/data --gpu -1

# æ¸…ç† GPU ç¼“å­˜
python -c "import jittor as jt; jt.clean_cache()"
```

### é—®é¢˜ 3: æ•°æ®åŠ è½½é”™è¯¯

**ç—‡çŠ¶ï¼š**

```
FileNotFoundError: [Errno 2] No such file or directory
ValueError: No images found in directory
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ£€æŸ¥æ•°æ®é›†è·¯å¾„
ls -R /path/to/RAF-DB/train/

# ç¡®ä¿ç›®å½•ç»“æ„æ­£ç¡®
# åº”è¯¥æ˜¯: data/train/0/, data/train/1/, ... data/train/6/
# æ¯ä¸ªå­ç›®å½•åŒ…å«å¯¹åº”ç±»åˆ«çš„å›¾åƒ

# éªŒè¯å›¾åƒæ ¼å¼
file /path/to/RAF-DB/train/0/*.jpg

# å¦‚æœè·¯å¾„åŒ…å«ç©ºæ ¼ï¼Œä½¿ç”¨å¼•å·
python main.py --data "/path/with spaces/RAF-DB"
```

### é—®é¢˜ 4: æ¨¡å‹åŠ è½½å¤±è´¥

**ç—‡çŠ¶ï¼š**

```
KeyError: 'state_dict'
pickle.UnpicklingError: ...
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# æ£€æŸ¥æ£€æŸ¥ç‚¹æ–‡ä»¶æ ¼å¼
import pickle
with open('checkpoint/model.pth', 'rb') as f:
    checkpoint = pickle.load(f)
    print(checkpoint.keys())  # åº”è¯¥åŒ…å« 'state_dict'

# ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åŠ è½½æ–¹å¼
model.load_state_dict(checkpoint['state_dict'])

# å¦‚æœæ£€æŸ¥ç‚¹æŸåï¼Œä»å¤‡ä»½æ¢å¤
# æˆ–é‡æ–°è®­ç»ƒæ¨¡å‹
```

### é—®é¢˜ 5: è®­ç»ƒé€Ÿåº¦æ…¢

**ç—‡çŠ¶ï¼š**

- æ¯ä¸ª epoch è€—æ—¶è¿‡é•¿
- GPU åˆ©ç”¨ç‡ä½

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹æ•°
python main.py --data /path/to/data --workers 4

# å¢åŠ æ‰¹æ¬¡å¤§å°ï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰
python main.py --data /path/to/data --batch-size 256

# æ£€æŸ¥ GPU ä½¿ç”¨æƒ…å†µ
nvidia-smi

# å…³é—­ä¸å¿…è¦çš„åå°è¿›ç¨‹
# åœ¨ Linux ä¸Šï¼šps aux | grep python
```

### é—®é¢˜ 6: å‡†ç¡®ç‡ä¸æé«˜

**ç—‡çŠ¶ï¼š**

- è®­ç»ƒå‡†ç¡®ç‡åœæ»
- éªŒè¯å‡†ç¡®ç‡ä¸‹é™ï¼ˆè¿‡æ‹Ÿåˆï¼‰

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# è°ƒæ•´å­¦ä¹ ç‡
python main.py --data /path/to/data --lr 0.00001

# å¢åŠ æƒé‡è¡°å‡
python main.py --data /path/to/data --wd 5e-4

# ä½¿ç”¨ä¸åŒçš„ä¼˜åŒ–å™¨
python main.py --data /path/to/data --optimizer adamw

# æ£€æŸ¥æ•°æ®å¢å¼ºæ˜¯å¦è¿‡å¼º
# ç¼–è¾‘ main.py ä¸­çš„ RandomErasing å‚æ•°

# éªŒè¯æ•°æ®é›†æ ‡ç­¾æ˜¯å¦æ­£ç¡®
# æ£€æŸ¥ data/train/ ç›®å½•ç»“æ„
```

### é—®é¢˜ 7: å†…å­˜æº¢å‡ºï¼ˆOOMï¼‰

**ç—‡çŠ¶ï¼š**

```
MemoryError
RuntimeError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# é€æ­¥å‡å°æ‰¹æ¬¡å¤§å°
python main.py --data /path/to/data --batch-size 16

# å‡å°‘æ•°æ®åŠ è½½çº¿ç¨‹
python main.py --data /path/to/data --workers 0

# æ¸…ç† GPU ç¼“å­˜
python -c "import jittor as jt; jt.clean_cache()"

# ç›‘æ§å†…å­˜ä½¿ç”¨
watch -n 1 nvidia-smi

# å¦‚æœä»ç„¶ä¸è¶³ï¼Œè€ƒè™‘ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
# éœ€è¦ä¿®æ”¹ main.py ä»£ç 
```

### é—®é¢˜ 8: é¢„è®­ç»ƒæƒé‡åŠ è½½å¤±è´¥

**ç—‡çŠ¶ï¼š**

```
FileNotFoundError: models/pretrain/ir50.pth not found
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ£€æŸ¥é¢„è®­ç»ƒæƒé‡æ–‡ä»¶
ls -lh models/pretrain/

# ç¡®ä¿æ–‡ä»¶å®Œæ•´ï¼ˆæ£€æŸ¥æ–‡ä»¶å¤§å°ï¼‰
# ir50.pth åº”è¯¥çº¦ 100+ MB
# mobilefacenet_model_best.pth åº”è¯¥çº¦ 10+ MB

# å¦‚æœæ–‡ä»¶ç¼ºå¤±ï¼Œä»åŸå§‹æ¥æºé‡æ–°ä¸‹è½½
# æˆ–ä»å¤‡ä»½æ¢å¤

# éªŒè¯æ–‡ä»¶å¯è¯»æ€§
file models/pretrain/ir50.pth
```

### é—®é¢˜ 9: æ··æ·†çŸ©é˜µç”Ÿæˆå¤±è´¥

**ç—‡çŠ¶ï¼š**

```
ValueError: y_true and y_pred must have same length
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# æ£€æŸ¥ main.py ä¸­çš„æ··æ·†çŸ©é˜µè®¡ç®—ä»£ç 
# ç¡®ä¿é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾ç»´åº¦åŒ¹é…

# éªŒè¯æ ‡ç­¾æ•°é‡
print(f"é¢„æµ‹æ•°: {len(y_pred)}")
print(f"çœŸå®æ ‡ç­¾æ•°: {len(y_true)}")

# å¦‚æœä¸åŒ¹é…ï¼Œæ£€æŸ¥æ•°æ®åŠ è½½å’Œé¢„æµ‹ä»£ç 
```

### é—®é¢˜ 10: æ—¥å¿—æ–‡ä»¶å†™å…¥å¤±è´¥

**ç—‡çŠ¶ï¼š**

```
PermissionError: [Errno 13] Permission denied: './log/...'
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# æ£€æŸ¥ log ç›®å½•æƒé™
ls -ld ./log/

# åˆ›å»º log ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
mkdir -p ./log

# ä¿®æ”¹æƒé™
chmod 755 ./log

# æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h

# å¦‚æœç£ç›˜æ»¡ï¼Œæ¸…ç†ä¸éœ€è¦çš„æ–‡ä»¶
```

---

## ğŸ” å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•åœ¨ Windows ä¸Šè¿è¡Œï¼Ÿ

**A:** å»ºè®®ä½¿ç”¨ä»¥ä¸‹æ–¹æ¡ˆï¼š

1. **WSL2 (Windows Subsystem for Linux 2)**ï¼šåœ¨ WSL2 ä¸­å®‰è£… Linux ç¯å¢ƒå¹¶è¿è¡Œ
2. **Docker**ï¼šä½¿ç”¨ Docker å®¹å™¨è¿è¡Œ
3. **è¿œç¨‹æœåŠ¡å™¨**ï¼šåœ¨ Linux æœåŠ¡å™¨ä¸Šè¿è¡Œ

### Q2: å¦‚ä½•ä½¿ç”¨å¤š GPU è®­ç»ƒï¼Ÿ

**A:** å½“å‰ç‰ˆæœ¬æ”¯æŒå• GPU è®­ç»ƒã€‚å¤š GPU æ”¯æŒéœ€è¦ä¿®æ”¹ä»£ç ä»¥ä½¿ç”¨ Jittor çš„åˆ†å¸ƒå¼è®­ç»ƒ APIã€‚

### Q3: å¦‚ä½•è°ƒæ•´å­¦ä¹ ç‡ï¼Ÿ

**A:** ä½¿ç”¨ `--lr` å‚æ•°ï¼š

```bash
python main.py --data /path/to/data --lr 0.00005
```

å­¦ä¹ ç‡è°ƒåº¦å™¨ä½¿ç”¨æŒ‡æ•°è¡°å‡ï¼š`gamma=0.98`ï¼ˆæ¯ä¸ª epoch ä¹˜ä»¥ 0.98ï¼‰

### Q4: è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**A:** å‡å°æ‰¹æ¬¡å¤§å°ï¼š

```bash
python main.py --data /path/to/data --batch-size 64
```

---

## ğŸ“Š å®éªŒç»“æœè®°å½•

### è®­ç»ƒæ—¥å¿—åˆ†æ

```python
# åˆ†æè®­ç»ƒæ—¥å¿—
import re
import matplotlib.pyplot as plt

log_file = './log/[timestamp]log.txt'
accuracies = []
losses = []

with open(log_file, 'r') as f:
    for line in f:
        # æå–å‡†ç¡®ç‡
        acc_match = re.search(r'Accuracy (\d+\.\d+)', line)
        if acc_match:
            accuracies.append(float(acc_match.group(1)))

        # æå–æŸå¤±
        loss_match = re.search(r'Loss (\d+\.\d+)', line)
        if loss_match:
            losses.append(float(loss_match.group(1)))

# ç»˜åˆ¶æ›²çº¿
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(accuracies)
plt.title('Accuracy')
plt.xlabel('Iteration')
plt.ylabel('Accuracy (%)')

plt.subplot(1, 2, 2)
plt.plot(losses)
plt.title('Loss')
plt.xlabel('Iteration')
plt.ylabel('Loss')

plt.tight_layout()
plt.savefig('training_analysis.png')
```

### æ€§èƒ½åŸºå‡†

| é…ç½®     | æ•°æ®é›† | å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´/epoch | æ¨ç†æ—¶é—´/æ ·æœ¬ |
| -------- | ------ | ------ | -------------- | ------------- |
| åŸºç¡€é…ç½® | RAF-DB | ~90%   | ~5 min         | ~50 ms        |
| ä¼˜åŒ–é…ç½® | RAF-DB | ~90%   | ~3 min         | ~30 ms        |
| é‡åŒ–æ¨¡å‹ | RAF-DB | ~89%   | ~2 min         | ~15 ms        |

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0 (2026-02-23)

- âœ… å®Œæ•´çš„ POSTER V2 Jittor å¤ç°
- âœ… æ”¯æŒ RAF-DBã€AffectNet-7ã€CAER-S æ•°æ®é›†
- âœ… SAM ä¼˜åŒ–å™¨å®ç°
- âœ… 7 ç±»å’Œ 8 ç±»åˆ†ç±»æ”¯æŒ
- âœ… è¯¦ç»†çš„æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç 
- âœ… æ•…éšœæ’é™¤æŒ‡å—

---

## ğŸ“– å‚è€ƒèµ„æº

### è®ºæ–‡

- **POSTER V2**: [[[2301.12149\] POSTER++: A simpler and stronger facial expression recognition network](https://arxiv.org/abs/2301.12149)]
- **POSTER V1**: å‰ä½œå‚è€ƒ

### ç›¸å…³é¡¹ç›®

- [Jittor å®˜æ–¹æ–‡æ¡£](https://cg.cs.tsinghua.edu.cn/jittor/)
- [Talented-Q/POSTER_V2](https://github.com/Talented-Q/POSTER_V2?tab=readme-ov-file)

### æ•°æ®é›†

- [RAF-DB]([RAF-DB DATASET](https://www.kaggle.com/datasets/shuvoalok/raf-db-dataset?resource=download))
- [AffectNet]([Databases | Dr. Mohammad H. Mahoor, Ph.D. Professor of Electrical & Computer Engineering at University of Denver](https://mohammadmahoor.com/pages/databases/affectnet/))
- [CAER-S]([CAER (ICCV 2019)](https://caer-dataset.github.io/))

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªåŸè®ºæ–‡çš„è®¸å¯è¯è¦æ±‚ã€‚

---

**æœ€åæ›´æ–°**: 2026-02-23
